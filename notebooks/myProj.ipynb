{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import string, re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('C:/Users/hp/Desktop/HateSpeech/onlineDatasets/caa-tweets-till-9012020/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'mentions', 'urls',\n",
       "       'photos', 'replies_count', 'retweets_count', 'likes_count', 'hashtags',\n",
       "       'cashtags', 'link', 'retweet', 'quote_url', 'video', 'near', 'geo',\n",
       "       'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to',\n",
       "       'retweet_date', 'translate', 'trans_src', 'trans_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = tweets_df[:190000]\n",
    "caa_tweets = all_tweets.tweet\n",
    "hashtags = all_tweets.hashtags\n",
    "date = all_tweets.date\n",
    "retweets_count = all_tweets.retweets_count\n",
    "likes_count = all_tweets.likes_count\n",
    "useful_tweets = list(zip(caa_tweets,date, hashtags, retweets_count, likes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate hindi and others\n",
    "\n",
    "def separate_english_hindi_tweets(tweets):\n",
    "    etweets = []\n",
    "    htweets= []\n",
    "    \n",
    "    for t, tweet_tup in enumerate(tweets):\n",
    "        e_flag = 1\n",
    "        tweet = tweet_tup[0]\n",
    "        for c in tweet:\n",
    "            if c == \"\\n\":\n",
    "                continue\n",
    "            if ord(c) > 31 and ord(c) < 127:\n",
    "                continue\n",
    "            elif ord(c) > 2300 and ord(c) < 2400: # hindi\n",
    "                e_flag = 0\n",
    "                htweets.append(tweet_tup)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        if e_flag == 1:\n",
    "            etweets.append(tweet_tup)\n",
    "            \n",
    "    return etweets, htweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets = []\n",
    "hindi_tweets = []\n",
    "english_tweets, hindi_tweets = separate_english_hindi_tweets(useful_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate English from others\n",
    "\n",
    "etweets = []\n",
    "otweets= []\n",
    "    \n",
    "for t, etup in enumerate(english_tweets):\n",
    "    e_flag = 1\n",
    "    tweet = etup[0]\n",
    "    for c in tweet:\n",
    "        if c == \"\\n\":\n",
    "            continue\n",
    "        if ord(c) > 31 and ord(c) < 250:\n",
    "            continue\n",
    "        elif ord(c) > 8200 and ord(c) < 8400: #special punctuations\n",
    "            continue\n",
    "        elif ord(c) > 9000: #smileys\n",
    "            continue\n",
    "        else:\n",
    "#             print(c, ord(c))\n",
    "            e_flag = 0\n",
    "            break\n",
    "    if e_flag == 1:\n",
    "        etweets.append(etup)\n",
    "    else:\n",
    "        otweets.append(etup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Yet another reason why India needs #CAA: \\n\\nHindus Beaten by Pakistani Police for Hoisting Saffron Flag in Their Own Home. Video Published to Cower Other Hindus into Submission!\\n\\n https://www.youtube.com/watch?v=lTQxDeBmCyI\\xa0‚Ä¶\\n@MEAIndia @Swamy39 @blsanthosh @davidfrawleyved @MODIfiedVikas @ShefVaidya',\n",
       " '2020-01-08',\n",
       " \"['#caa']\",\n",
       " 0,\n",
       " 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_sorted_tweets = sorted(etweets, key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#CAA + #NRC + more this Sunday on @patriotact pic.twitter.com/AIoAub8Fwu',\n",
       "  '2019-12-20',\n",
       "  \"['#caa', '#nrc']\",\n",
       "  17739,\n",
       "  42902),\n",
       " ('My university üòç\\nStudents of #PanjabUniversity in support of #CAA\\nChandigarh is not only beautiful, but Nationalist too ‚ù§Ô∏è  pic.twitter.com/NUgngteXur',\n",
       "  '2019-12-18',\n",
       "  \"['#panjabuniversity', '#caa']\",\n",
       "  9247,\n",
       "  28077),\n",
       " ('Stop watching Hindi movies of the actors, directors, writers, anyone who has supported the violent protests, looting and arson by Muzlims over #CAA. This is ONLY way to teach them a lesson. Starve them of money.',\n",
       "  '2019-12-18',\n",
       "  \"['#caa']\",\n",
       "  8570,\n",
       "  21134),\n",
       " ('Delhi with #CAA\\nDelhi with @narendramodi \\nDelhi with @AmitShah pic.twitter.com/pDgdIoZLvh',\n",
       "  '2019-12-20',\n",
       "  \"['#caa']\",\n",
       "  8561,\n",
       "  20395),\n",
       " ('#CAA is meant to provide fast track citizenship to non-Muslim families from Afghanistan, Pakistan and Bangladesh that have been lynched, raped and persecuted for generations due to their religious beliefs. \\n\\nWhatever side you‚Äôre on, make sure it‚Äôs the compassionate one.',\n",
       "  '2019-12-19',\n",
       "  \"['#caa']\",\n",
       "  6807,\n",
       "  18983),\n",
       " ('Muslims in #India are protesting against fast-tracking of citizenship to non-Muslims persecuted for decades by Muslims in Afghanistan, Pakistan and Bangladesh. \\n\\nü§∑üèª\\u200d‚ôÇÔ∏è\\n\\n‚ÄúThera mera rishta kya?‚Äù #CAA #BharatBananaHai https://twitter.com/anaz_oam/status/1210508671219748864\\xa0‚Ä¶',\n",
       "  '2019-12-30',\n",
       "  \"['#india', '#caa', '#bharatbananahai']\",\n",
       "  6493,\n",
       "  15796),\n",
       " ('It is not the #CAA they hate. They hate Hindus. That means you and me.  pic.twitter.com/3jzvUixwNv',\n",
       "  '2019-12-20',\n",
       "  \"['#caa']\",\n",
       "  6330,\n",
       "  12586),\n",
       " (\"So its Clear now Protest against #CAA is not for Political/Democratic Reason it's Ghazwa-E-Hind,Anti Hindu and Pure Fanatic Islamic Movement.  pic.twitter.com/ElR26LqOz2\",\n",
       "  '2019-12-30',\n",
       "  \"['#caa']\",\n",
       "  5850,\n",
       "  11233),\n",
       " ('Citizenship Amendment Act is too little compassion coming too late. -Sg  #CAA #NRC #CAAProtests https://www.youtube.com/watch?v=11RgVkZcPjY\\xa0‚Ä¶',\n",
       "  '2019-12-29',\n",
       "  \"['#caa', '#nrc', '#caaprotests']\",\n",
       "  5814,\n",
       "  15645),\n",
       " ('Modi, Omith Sho Murdobod..!\\nShoiton, Birodhi..!\\nGuess the language - Bengali.\\nGuess the place ? Parakkadavu, Kerala.\\nNow you know how serious the problem of illegal Bangladeshi is.. !\\n#CAA\\n#NRC_CAA pic.twitter.com/Ra0JKsJBef',\n",
       "  '2019-12-20',\n",
       "  \"['#caa', '#nrc_caa']\",\n",
       "  5683,\n",
       "  6382)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweet_sorted_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_sorted_tweets = sorted(etweets, key=lambda x: x[4], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#CAA + #NRC + more this Sunday on @patriotact pic.twitter.com/AIoAub8Fwu',\n",
       "  '2019-12-20',\n",
       "  \"['#caa', '#nrc']\",\n",
       "  17739,\n",
       "  42902),\n",
       " ('My university üòç\\nStudents of #PanjabUniversity in support of #CAA\\nChandigarh is not only beautiful, but Nationalist too ‚ù§Ô∏è  pic.twitter.com/NUgngteXur',\n",
       "  '2019-12-18',\n",
       "  \"['#panjabuniversity', '#caa']\",\n",
       "  9247,\n",
       "  28077),\n",
       " ('Stop watching Hindi movies of the actors, directors, writers, anyone who has supported the violent protests, looting and arson by Muzlims over #CAA. This is ONLY way to teach them a lesson. Starve them of money.',\n",
       "  '2019-12-18',\n",
       "  \"['#caa']\",\n",
       "  8570,\n",
       "  21134),\n",
       " ('India stands strong with Hon @narendramodi ji & Hon @AmitShah ji for solving decades old problem by #CAA & giving new lease of life in Bharat, to our brothers & sisters facing religious persecution in neighbouring countries.\\n\\n(Siliguri #WestBengal on 24 Dec ‚Äò19)\\n#IndiaSupportsCAA pic.twitter.com/EnUURXAWol',\n",
       "  '2019-12-30',\n",
       "  \"['#caa', '#westbengal', '#indiasupportscaa']\",\n",
       "  5019,\n",
       "  20672),\n",
       " ('The United Muslim Action Committee will be holding a protest meeting on 21 December 2019 (6 PM to 10 PM) against #CAA & #NRC\\n\\nI‚Äôll be addressing FELLOW INDIANS along with religious scholars & AIMIM legislators\\n\\nThis is our home & no one can force us to behave like it‚Äôs not',\n",
       "  '2019-12-17',\n",
       "  \"['#caa', '#nrc']\",\n",
       "  5317,\n",
       "  20545),\n",
       " ('Delhi with #CAA\\nDelhi with @narendramodi \\nDelhi with @AmitShah pic.twitter.com/pDgdIoZLvh',\n",
       "  '2019-12-20',\n",
       "  \"['#caa']\",\n",
       "  8561,\n",
       "  20395),\n",
       " ('#CAA is meant to provide fast track citizenship to non-Muslim families from Afghanistan, Pakistan and Bangladesh that have been lynched, raped and persecuted for generations due to their religious beliefs. \\n\\nWhatever side you‚Äôre on, make sure it‚Äôs the compassionate one.',\n",
       "  '2019-12-19',\n",
       "  \"['#caa']\",\n",
       "  6807,\n",
       "  18983),\n",
       " ('Muslims in #India are protesting against fast-tracking of citizenship to non-Muslims persecuted for decades by Muslims in Afghanistan, Pakistan and Bangladesh. \\n\\nü§∑üèª\\u200d‚ôÇÔ∏è\\n\\n‚ÄúThera mera rishta kya?‚Äù #CAA #BharatBananaHai https://twitter.com/anaz_oam/status/1210508671219748864\\xa0‚Ä¶',\n",
       "  '2019-12-30',\n",
       "  \"['#india', '#caa', '#bharatbananahai']\",\n",
       "  6493,\n",
       "  15796),\n",
       " ('Citizenship Amendment Act is too little compassion coming too late. -Sg  #CAA #NRC #CAAProtests https://www.youtube.com/watch?v=11RgVkZcPjY\\xa0‚Ä¶',\n",
       "  '2019-12-29',\n",
       "  \"['#caa', '#nrc', '#caaprotests']\",\n",
       "  5814,\n",
       "  15645),\n",
       " ('Telangana supports #CAA !\\n\\n#IndiawithCAA \\n\\n| @narendramodi @AmitShah @JPNadda @BJP4India @BJP4Telangana | pic.twitter.com/GpLSkygQMy',\n",
       "  '2019-12-30',\n",
       "  \"['#caa', '#indiawithcaa']\",\n",
       "  3318,\n",
       "  15273)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_sorted_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for counting the number of tweets on that particular date as key-value pair\n",
    "\n",
    "dates = defaultdict(int)\n",
    "def count_date_tweets(tweet_tups):\n",
    "    for tt in tweet_tups:\n",
    "        dates[tt[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_date_tweets(etweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_per_date = list(dates.values())\n",
    "dates_for_tweets = list(dates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove urls, hashtags and punctuations\n",
    "\n",
    "#import re,string\n",
    "\n",
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in str(etweets):\n",
    "    strip_all_entities(strip_links(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "# split into words\n",
    "#from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(str(etweets))\n",
    "\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "\n",
    "# remove punctuation from each word\n",
    "#import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "# filter out stop words\n",
    "#from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#print(stop_words)\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:1000])\n",
    "print('\\n')\n",
    "\n",
    "# stemming of words\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "#stemmed = [porter.stem(word) for word in tokens]\n",
    "stemmed = [porter.stem(word) for word in words]\n",
    "print(stemmed[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization using NLTK\n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize: Split the sentence into words\n",
    "#word_list = nltk.word_tokenize(str(etweets))\n",
    "#word_list = nltk.word_tokenize(str(words))\n",
    "word_list = nltk.word_tokenize(str(stemmed))\n",
    "\n",
    "# Lemmatize list of words and join\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the frequency of words\n",
    "\n",
    "freqDict=dict()\n",
    "\n",
    "for tweet in etweets:\n",
    "   #words=tweet.split()\n",
    "   for word in words:\n",
    "        if word not in freqDict:\n",
    "            freqDict[word] = 1\n",
    "        else:\n",
    "            freqDict[word] += 1\n",
    "print(freqDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "\n",
    "#import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(etweets)\n",
    "\n",
    "d= dict()\n",
    "for x in nlp(str(doc)).ents:\n",
    "    d[str(x)]= x.label_ \n",
    "\n",
    "for x,y in d.items():\n",
    "    if y == 'PERSON':\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
